{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"dhito2-openmv\\\\trained.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_x:0', 'index': 0, 'shape': array([ 1, 32, 32,  1]), 'shape_signature': array([ 1, 32, 32,  1]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003921568859368563, -128), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 14, 'shape': array([1, 2]), 'shape_signature': array([1, 2]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serving_default': {'inputs': ['x'], 'outputs': ['output_0']}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_signature_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "with open(\"dhito2-openmv\\labels.txt\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # print(f\"Original image shape: {image.shape}\")\n",
    "    \n",
    "    # Resize to 32x32\n",
    "    resized = cv2.resize(image, (32, 32))\n",
    "    # print(f\"Resized image shape: {resized.shape}\")\n",
    "    \n",
    "    # Normalize the image\n",
    "    normalized = resized / 255.0\n",
    "    # print(f\"Normalized image: {normalized}\")\n",
    "    \n",
    "    # Scale and quantize the image to int8\n",
    "    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "\n",
    "    input_data = (normalized / input_scale + input_zero_point).astype(np.int8)\n",
    "    # print(f\"Quantized input data: {input_data}\")\n",
    "    \n",
    "    return image, resized, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path):\n",
    "    original_image, resized_image, input_data = preprocess_image(image_path)\n",
    "    \n",
    "    # Add batch dimension to input data\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    input_data = np.expand_dims(input_data, axis=-1)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    # print(f\"Raw output data: {output_data}\")\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "    # print(f\"Output scale: {output_scale}, Output zero point: {output_zero_point}\")\n",
    "    predictions = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",
    "    # print(f\"Dequantized output data: {predictions}\")\n",
    "\n",
    "    # Display the results\n",
    "    for i, prob in enumerate(predictions[0]):\n",
    "        print(f\"{labels[i]}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image, resized_image, input_data = preprocess_image('img\\matatutup.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original Image', original_image)\n",
    "cv2.imshow('Resized Image', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buka: 0.1641\n",
      "tutup: 0.8359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classify_image('img\\matatutup.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
